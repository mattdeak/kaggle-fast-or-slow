{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec88d185-a9af-4979-b8a3-8f56fb6ece9e",
   "metadata": {},
   "source": [
    "# Model Exporting Notebook\n",
    "\n",
    "This notebook takes a model and exports:\n",
    "\n",
    "1. Test Predictions\n",
    "2. MC Test predictions (if applicable)\n",
    "3. Train/Valid prediction (for downstream stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a3837b-11b7-4900-bcfb-0cca3bc8ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = \"6aeax7xs\"\n",
    "\n",
    "import os\n",
    "os.chdir('/root/kaggle-fast-or-slow')\n",
    "\n",
    "from ml.layout_v1.model import GraphMLP\n",
    "from ml.layout_v1.dataset import LayoutDataset\n",
    "from ml.layout_v1.job.spec import PreprocessorSpec, PostprocessorSpec, JobSpec\n",
    "from ml.layout_v1.job.builder import build_processors, fit_node_processor\n",
    "from ml.layout_v1.job.constants import GLOBAL_POOLINGS\n",
    "from ml.layout_v1.preprocessors import GlobalFeatureGenerator\n",
    "import torch_geometric\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "import wandb\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7379f59d-0c03-4739-92a8-b65b4bfc2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to fit\n",
    "TRAIN_DATA_DIRS = [\"data/layout/nlp/default/train\", \"data/layout/nlp/random/train\"]\n",
    "TEST_DATA_DIRS = [\"data/layout/nlp/default/test\", \"data/layout/nlp/random/test\"]\n",
    "\n",
    "WANDB_RUN_ID = f\"kaggle-fast-or-slow/{RUN_ID}\"\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(WANDB_RUN_ID)\n",
    "\n",
    "config = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9017d89-5234-4c8c-9145-e89cebe03d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node processor\n"
     ]
    }
   ],
   "source": [
    "job_spec = JobSpec(**config)\n",
    "\n",
    "preprocessor_spec = PreprocessorSpec(**config[\"preprocessors\"])\n",
    "postprocessor_spec = PostprocessorSpec(**config[\"postprocessors\"])\n",
    "\n",
    "preprocessors = build_processors(preprocessor_spec)\n",
    "postprocessors = build_processors(postprocessor_spec)\n",
    "\n",
    "if preprocessors.node_transform:\n",
    "    if hasattr(preprocessors.node_transform, \"fit\"):\n",
    "        preprocessors.node_transform = fit_node_processor(\n",
    "            TRAIN_DATA_DIRS, preprocessors.node_transform\n",
    "        )\n",
    "\n",
    "if postprocessors.node_transform:\n",
    "    if hasattr(postprocessors.node_transform, \"fit\"):\n",
    "        postprocessors.node_transform = fit_node_processor(\n",
    "            TRAIN_DATA_DIRS, postprocessors.node_transform\n",
    "        )\n",
    "\n",
    "# Manually add global processor cause automating it is a pain cause I'm a bad dev\n",
    "global_random_preprocessor = GlobalFeatureGenerator(\"nlp\",\"random\",True)\n",
    "global_default_preprocessor = GlobalFeatureGenerator(\"nlp\",\"default\",True)\n",
    "\n",
    "random_preprocessors = deepcopy(preprocessors)\n",
    "random_preprocessors.global_transform = global_random_preprocessor\n",
    "\n",
    "default_preprocessors = deepcopy(preprocessors)\n",
    "default_preprocessors.global_transform = global_default_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667b6b8c-2b1a-4485-98a7-da2c96d54ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3414a77306f94442a1e85e1639b7213b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35c6e0dcb5d4eba98a865e1fbc79f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Data\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "default_dataset = LayoutDataset(\n",
    "    directories=[\"data/layout/nlp/default/test\"],\n",
    "    processed_dir=\"data/processed_test\",\n",
    "    pretransforms=default_preprocessors,\n",
    "    posttransforms=postprocessors,\n",
    "    multiprocess=False,\n",
    "    force_reload=False\n",
    ")\n",
    "\n",
    "random_dataset = LayoutDataset(\n",
    "    directories=[\"data/layout/nlp/random/test\"],\n",
    "    processed_dir=\"data/processed_test\",\n",
    "    pretransforms=random_preprocessors,\n",
    "    posttransforms=postprocessors,\n",
    "    multiprocess=False,\n",
    "    force_reload=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d4175c-b7cc-4589-8f52-749d2b6619a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = default_dataset.get(0).x.shape[1]\n",
    "num_global_features = default_dataset.get(0).global_features.shape[1]\n",
    "\n",
    "pooling = GLOBAL_POOLINGS[job_spec.pooling]\n",
    "\n",
    "\n",
    "model = GraphMLP(\n",
    "    graph_input_dim=num_features,\n",
    "    global_features_dim=num_global_features,\n",
    "    graph_channels=job_spec.graph_channels,\n",
    "    graph_layers=job_spec.graph_layers,\n",
    "    linear_channels=job_spec.linear_channels,\n",
    "    linear_layers=job_spec.linear_layers,\n",
    "    dropout=job_spec.dropout,\n",
    "    pooling_fn=pooling,\n",
    "    pooling_feature_multiplier=job_spec.pooling_feature_multiplier,\n",
    "    graph_conv=job_spec.graph_convolution_type,\n",
    "    graph_conv_kwargs=job_spec.graph_convolution_kwargs,\n",
    "    graph_norm=job_spec.graph_norm,\n",
    "    linear_norm=job_spec.linear_norm,\n",
    "    use_multi_edge=job_spec.use_multi_edge,\n",
    "    main_block=job_spec.main_block,\n",
    "    alt_block=job_spec.alt_block,\n",
    ")\n",
    "\n",
    "model = model.to(\"cuda\")\n",
    "model = torch_geometric.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "672fc279-58f4-4628-a698-bd907480ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most recent checkpoint\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "paths = sorted(Path(f\"models/{RUN_ID}\").iterdir(), key=os.path.getmtime)\n",
    "most_recent = str(paths[0].absolute())\n",
    "\n",
    "state_dict = torch.load(most_recent)\n",
    "model.load_state_dict(state_dict[\"model_state_dict\"])\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058771b1-2902-4c6e-b9ce-07294e1bff1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4086ff3-6f95-4558-be1c-142534f85d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_id_from_file(filepath: str):\n",
    "    file_id = filepath.removeprefix(\"data/\").removesuffix(\".npz\")\n",
    "    file_id = file_id.replace(\"/test\",\"\")\n",
    "    file_id = file_id.replace(\"/\",\":\")\n",
    "    \n",
    "    return file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4911fd-8805-4929-a2fe-ad888c3317ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dacc6d24604ff09cb902cc4d79cef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/opt/conda/lib/python3.10/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "results = defaultdict(dict)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "MC_DROPOUT_ITERS = 20\n",
    "\n",
    "next_batch = []\n",
    "\n",
    "DATASETS = [random_dataset, default_dataset]\n",
    "\n",
    "model.eval()\n",
    "for dataset in DATASETS:\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        file_path, config_idx = dataset.idx_to_source_file_and_config[i]\n",
    "        file_id = make_id_from_file(file_path)\n",
    "        data = dataset.get(i)\n",
    "        next_batch.append((data, file_id, config_idx))\n",
    "        \n",
    "        if len(next_batch) == BATCH_SIZE or i == len(dataset) - 1:\n",
    "            batch_data = [d[0] for d in next_batch]\n",
    "            file_ids = [d[1] for d in next_batch]\n",
    "            config_ids = [d[2] for d in next_batch]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch = Batch.from_data_list(batch_data)\n",
    "                batch = batch.to('cuda')\n",
    "                output = model(batch).flatten()\n",
    "            \n",
    "            for o, f, c in zip(output.tolist(), file_ids, config_ids):\n",
    "                results[f][c] = o\n",
    "            \n",
    "            next_batch = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
